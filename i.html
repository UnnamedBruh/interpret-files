<audio id="audioPlay" controls></audio>
<input type="file" id="fileInput">
<hr>
<canvas width="256" height="256" id="visualizer"></canvas>

<script>
  const audioPlayer = document.getElementById("audioPlay");
  const canvas = document.getElementById("visualizer");
  const s = canvas.getContext("2d");

  const audioContext = new (window.AudioContext || window.webkitAudioContext)();
  const analyser = audioContext.createAnalyser();
  analyser.fftSize = 256; // Set the size of FFT (number of frequency bins)

  let audioData = null;
  let exporter;

  // Handle file input
  document.getElementById("fileInput").addEventListener('change', (event) => {
    const file = event.target.files[0];
    if (file) {
      const reader = new FileReader();
      reader.onload = function(e) {
        const arrayBuffer = e.target.result;
        const mode = parseFloat(prompt("What mode should be used for the interpretation process? 0 = basic interpretation: file data is interpreted as audio in the way it was organized.")) >>> 0;
        if (mode === 0) {
          audioData = new Int8Array(arrayBuffer);
        }
        exporter = new AudioExporter(audioData, Number(prompt("Enter the sample rate of the audio (48000 will be the default if invalid input, or input not received).") || 48000), 1);
        if (audioPlayer.src) URL.revokeObjectURL(audioPlayer.src);
        audioPlayer.src = URL.createObjectURL(exporter.convertToWav());
        alert("The result may contain high-frequency data for variable audio.");
        
        // Start visualizer when audio is loaded
        audioPlayer.play();
        setupAudioContext();
      };
      reader.readAsArrayBuffer(file);
    }
  });

  // Set up audio context and analyser
  function setupAudioContext() {
    const source = audioContext.createBufferSource();
    fetch(audioPlayer.src)
      .then(response => response.arrayBuffer())
      .then(buffer => audioContext.decodeAudioData(buffer))
      .then(decodedData => {
        source.buffer = decodedData;
        source.connect(analyser);
        analyser.connect(audioContext.destination);
        source.start(0);
      });
  }

  // Update the visualizer every frame
  function update() {
    s.fillStyle = "rgba(0,0,0,1)";
    s.fillRect(0, 0, canvas.width, canvas.height);

    if (audioData && audioData.length !== 0) {
      // Create a buffer for the frequency data
      const frequencyData = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(frequencyData);

      // Visualize data as a grid of colors
      const gridWidth = 16;
      const gridHeight = 16;
      const blockWidth = canvas.width / gridWidth;
      const blockHeight = canvas.height / gridHeight;

      for (let x = 0; x < gridWidth; x++) {
        for (let y = 0; y < gridHeight; y++) {
          const index = (y * gridWidth + x) * 2;
          const colorValue = frequencyData[index % frequencyData.length];

          // Generate a color based on the frequency value
          const r = (colorValue % 256);
          const g = (colorValue * 2) % 256;
          const b = (colorValue * 3) % 256;
          const alpha = 0.5 + Math.abs(Math.sin(colorValue / 255));

          const rgba = `rgba(${r},${g},${b},${alpha})`;

          s.fillStyle = rgba;
          s.fillRect(x * blockWidth, y * blockHeight, blockWidth, blockHeight);
        }
      }
    }

    requestAnimationFrame(update);
  }

  update(); // Start the visualization loop

</script>
