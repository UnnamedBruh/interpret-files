<audio id="audioPlay" controls></audio>
<input type="file" id="fileInput">
<hr>
<select id="visualType"><option>Waterfall</option><option>Waveform</option></select>
<p id="description"></p>
<canvas width="256" height="256" id="visualizer">
<script>const audioPlayer = document.getElementById("audioPlay"), wa = document.getElementById("visualizer");
const s = wa.getContext("2d");
const options = [...document.querySelectorAll("option")], choice = document.getElementById("visualType"), desc = document.getElementById("description");
class AudioExporter {
    constructor(audioData, sampleRate, channels, bits) {
        this.audioData = audioData;
        this.sampleRate = sampleRate;
        this.channels = channels;
        this.bits = bits;
    }
    convertToWav() {
        const numChannels = this.channels, len = this.audioData.length;
        const len2 = len * (this.bits / 8);
        const buffer = new ArrayBuffer(44 + len2);
        const view = new DataView(buffer);
        this.writeString(view, 0, 'RIFF');
        view.setUint32(4, 36 + len2, true);
        this.writeString(view, 8, 'WAVE');
        this.writeString(view, 12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, numChannels, true);
        view.setUint32(24, this.sampleRate, true);
        view.setUint32(28, this.sampleRate * 2, true);
        view.setUint16(32, 2, true);
        view.setUint16(34, this.bits, true);
        this.writeString(view, 36, 'data');
        view.setUint32(40, len2, true);
        let offset = 44;
        if (this.bits === 8) {
            for (let i = 0; i < len; i++) {
                view.setInt8(offset, this.audioData[i], true);
                offset++;
            }
        } else {
            for (let i = 0; i < len; i++) {
                view.setInt16(offset, this.audioData[i], true);
                offset += 2;
            }
        }
        return new Blob([view], { type: 'audio/wav' });
    }
    writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i));
        }
    }
};

let audioData, exporter, bitmax, divis, shouldRedraw, point;
function update(forceRedraw) {
    if (audioData && audioData.length !== 0 && (shouldRedraw || forceRedraw || audioPlayer.currentTime !== point)) {
        console.log("Redraw requested");
        if (choice.value === "Waterfall") {
            wa.width = 256;
            wa.height = 256;
            const destination = Math.round(audioPlayer.currentTime * exporter.sampleRate / 64) * 64;
            let rgba;
            for (let x = 0; x < 64; x++) {
                for (let y = 0; y < 64; y++) {
                    const z = destination + x * 3 + y * 64;
                    if (z >= audioData.length) {
                        s.fillStyle = "rgb(0,0,0)";
                        s.fillRect(x * 4, y * 4, 4, 4);
                    } else {
                        rgba = "rgb(" + ((audioData[z] + bitmax) / divis) + "," + ((audioData[z + 1] + bitmax) / divis) + "," + ((audioData[z + 2] + bitmax) / divis) + ")";
                        s.fillStyle = rgba;
                        s.fillRect(x * 4, y * 4, 4, 4);
                    }
                }
            }
        } else if (choice.value === "Waveform") {
            wa.width = 512;
            wa.height = 256;
            s.fillStyle = "rgb(0,0,0)";
            s.fillRect(0, 0, 512, 256);
            const destination = Math.round(audioPlayer.currentTime * exporter.sampleRate);
            s.beginPath();
            s.moveTo(0, 128);
            for (let x = 0; x < 512; x++) {
                s.lineTo(x, ((audioData[destination + x] + bitmax) / divis));
            }
            s.strokeStyle = "rgb(255,255,255)";
            s.stroke();
        }
    }
    shouldRedraw = !audioPlayer.paused;
    point = audioPlayer.currentTime;
    if (!forceRedraw) requestAnimationFrame(()=>update());
}
update();
document.getElementById("fileInput").addEventListener('change', (event) => {
    const file = event.target.files[0]; // Get the first file
    if (file) {
        const reader = new FileReader();
        // When the file is successfully read (why does this sound like a meme?)
        reader.onload = function(e) {
            const arrayBuffer = e.target.result, mode = parseFloat(prompt("What mode should be used for the interpretation process? 0 = basic interpretation: file data is interpeted as audio in the way it was organized.")) >>> 0, bit = parseFloat(prompt("How many bits should each sample accept? (Default is 8 bits each)") || "8") >>> 0;
            if (bit !== 8 && bit !== 16) {
                alert("The amount of bits should be either 8 or 16. Defaulting to 8 bits instead.");
                bit = 8;
            }
            if (bit === 8) {
                if (mode === 0) {
                    audioData = new Int8Array(arrayBuffer); // LOOK, MOM!! I OPTIMIZED MY DATA INTERPRETATION STEPS!!! ISNT THAT COOL????
                }
            } else {
                if (mode === 0) {
                    if (arrayBuffer.byteLength % 2 === 0) {
                        audioData = new Int16Array(arrayBuffer); // I wonder what this sounds like when I interpret 16-bit WAV sounds... oh, they sound the same.
                    } else {
                        // OH, NOES! WE RAN INTO A PROBLEM!
                        const uint8 = new Uint8Array(Math.ceil(arrayBuffer.byteLength / 2) * 2);
                        uint8.set(new Uint8Array(arrayBuffer));
                        audioData = new Int16Array(uint8.buffer);
                    }
                }
            }
            exporter = new AudioExporter(audioData, Number(prompt("Enter in the sample rate of the audio (48000 will be the default if invalid input, or input not received).") || 48000), 1, bit);
            if (audioPlayer.src) URL.revokeObjectURL(audioPlayer.src);
            audioPlayer.src = URL.createObjectURL(exporter.convertToWav());
            alert("WARNING: THE RESULT OF THE AUDIO MAY CONTAIN VERY HIGH FREQUENCIES FOR DATA THAT MAY VARY A LOT!");
            bitmax = exporter.bits === 8 ? 128 : 32768;
            divis = exporter.bits === 8 ? 1 : 256;
            update(true);
        };
        // Read the file as an ArrayBuffer
        alert("The file has been uploaded to the tool (not sent to the internet). Pressing OK may begin the reading process."), reader.readAsArrayBuffer(file);
    }
});
s.strokeStyle = "rgb(255,255,255)";
s.lineWidth = 1;
s.lineCap = 'round';
s.lineJoin = 'bevel';
const map = ["Uses 4x4 RGB pixels to directly represent the audio data, where all of the pixels scroll up until the audio ends.", "Uses a white line on a black background to represent the audio data's volume."];
for (let i = 0; i < options.length; i++) {
    options[i].onmouseover = function() {
        description.textContent = map[i];
    }
    options[i].onmouseout = function() {
        description.textContent = "";
    }
}
</script>
